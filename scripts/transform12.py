import torch
from torch import nn

class NLTransform(nn.Module):
	def __init__(self):
		super(NLTransform, self).__init__()
		#Conv2d:		Dout = floor((Din + 2*padding - dilation*(kernel-1) - 1)/stride + 1)
		#ConvTranspose2d:	Dout = (Din-1)*stride - 2*padding + dilation*(kernel-1) + output_padding + 1
		self.activ=nn.LeakyReLU()

		#T12: D32W48-VR
		# nbits:	{2, 4, 6, 8}.  Number of bits per latent sample.
		# downsample:	{0, 1, 2}.  Downsample level. 0: not downsampled, 1: downsampled once, 2: downsampled twice
		self.nOptions=12
		#self.rate01=nn.Linear(self.nOptions, 256)
		#self.rate02=nn.Linear(256, 45)

		self.a_conv01=nn.Conv2d(self.nOptions+3, 48, 3, 1, 1)
		self.a_conv02=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv03=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv04=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv05=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv06=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv07=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv08=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv09=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv10=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv11=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv12=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv13=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv14=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv15=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv16=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv17=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv18=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv19=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv20=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv21=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv22=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv23=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv24=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv25=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv26=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv27=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv28=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv29=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv30=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv31=nn.Conv2d(48, 48, 3, 1, 1)
		self.a_conv32=nn.Conv2d(48,  3, 3, 1, 1)

		self.s_conv01=nn.Conv2d(self.nOptions+3, 48, 3, 1, 1)
		self.s_conv02=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv03=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv04=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv05=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv06=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv07=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv08=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv09=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv10=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv11=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv12=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv13=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv14=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv15=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv16=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv17=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv18=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv19=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv20=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv21=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv22=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv23=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv24=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv25=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv26=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv27=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv28=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv29=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv30=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv31=nn.Conv2d(48, 48, 3, 1, 1)
		self.s_conv32=nn.Conv2d(48,  3, 3, 1, 1)
	
	def decode_options(self, option):	# option = downsample<<2 | nbits = {0, ...11} (lowest to highest quality)
		return ((option&3)+1), 2-(option>>2)
	
	def prep_rate(self, option, shape, device):#returns (ratedata, nbits, downsample)
		nbits, downsample=self.decode_options(option)
		rate=torch.empty(shape[0]).fill_(option).long()
		rate=nn.functional.one_hot(rate, self.nOptions)
		rate=rate.float().to(device)
		rate=torch.squeeze(rate, dim=1)

		#rate=self.activ(self.rate01(rate))
		#rate=self.activ(self.rate02(rate))
		rate=rate[:, :, None, None]
		return rate.expand(-1, -1, shape[2], shape[3]), nbits, downsample

	def encode(self, x, rate):# no nonlinearity after last operation
		x=torch.cat((x, rate), dim=1)
		t=self.activ(self.a_conv01(x))
		x=self.activ(self.a_conv02(t))
		x=self.activ(self.a_conv03(x))
		t=self.activ(self.a_conv04(x)+t)
		x=self.activ(self.a_conv05(t))
		x=self.activ(self.a_conv06(x))
		x=self.activ(self.a_conv07(x))
		t=self.activ(self.a_conv08(x)+t)
		x=self.activ(self.a_conv09(t))
		x=self.activ(self.a_conv10(x))
		x=self.activ(self.a_conv11(x))
		t=self.activ(self.a_conv12(x)+t)
		x=self.activ(self.a_conv13(t))
		x=self.activ(self.a_conv14(x))
		x=self.activ(self.a_conv15(x))
		t=self.activ(self.a_conv16(x)+t)
		x=self.activ(self.a_conv17(t))
		x=self.activ(self.a_conv18(x))
		x=self.activ(self.a_conv19(x))
		t=self.activ(self.a_conv20(x)+t)
		x=self.activ(self.a_conv21(t))
		x=self.activ(self.a_conv22(x))
		x=self.activ(self.a_conv23(x))
		t=self.activ(self.a_conv24(x)+t)
		x=self.activ(self.a_conv25(t))
		x=self.activ(self.a_conv26(x))
		x=self.activ(self.a_conv27(x))
		t=self.activ(self.a_conv28(x)+t)
		x=self.activ(self.a_conv29(t))
		x=self.activ(self.a_conv30(x))
		t=self.activ(self.a_conv31(x)+t)
		x=self.a_conv32(t)
		return x

	def decode(self, x, rate):# clamp [0, 1] after last operation
		x=torch.cat((x, rate), dim=1)
		t=self.activ(self.s_conv01(x))
		x=self.activ(self.s_conv02(t))
		x=self.activ(self.s_conv03(x))
		t=self.activ(self.s_conv04(x)+t)
		x=self.activ(self.s_conv05(t))
		x=self.activ(self.s_conv06(x))
		x=self.activ(self.s_conv07(x))
		t=self.activ(self.s_conv08(x)+t)
		x=self.activ(self.s_conv09(t))
		x=self.activ(self.s_conv10(x))
		x=self.activ(self.s_conv11(x))
		t=self.activ(self.s_conv12(x)+t)
		x=self.activ(self.s_conv13(t))
		x=self.activ(self.s_conv14(x))
		x=self.activ(self.s_conv15(x))
		t=self.activ(self.s_conv16(x)+t)
		x=self.activ(self.s_conv17(t))
		x=self.activ(self.s_conv18(x))
		x=self.activ(self.s_conv19(x))
		t=self.activ(self.s_conv20(x)+t)
		x=self.activ(self.s_conv21(t))
		x=self.activ(self.s_conv22(x))
		x=self.activ(self.s_conv23(x))
		t=self.activ(self.s_conv24(x)+t)
		x=self.activ(self.s_conv25(t))
		x=self.activ(self.s_conv26(x))
		x=self.activ(self.s_conv27(x))
		t=self.activ(self.s_conv28(x)+t)
		x=self.activ(self.s_conv29(t))
		x=self.activ(self.s_conv30(x))
		t=self.activ(self.s_conv31(x)+t)
		x=self.s_conv32(t)
		x=torch.clamp(x, min=0, max=1)
		return x
